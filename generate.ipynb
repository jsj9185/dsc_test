{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72795e48-f18f-41cc-8c6f-55e3c58d5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110d1f00-b0f0-418c-b43b-76cbea5ef78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DSC/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch, gc\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "# from financerag.rerank import CrossEncoderReranker\n",
    "# from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder, BM25Retriever, HybridRetriever\n",
    "from financerag.tasks import ConvFinQA, FinanceBench, FinDER, FinQA, FinQABench, MultiHiertt, TATQA\n",
    "from financerag.generate import OpenAIGenerator, CustomGenerator\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b12c4d-5e6e-4bb7-adff-e80edf229b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qd4982518</td>\n",
       "      <td>dd4c4fb38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qd4982518</td>\n",
       "      <td>dd4c4ef80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qd4982518</td>\n",
       "      <td>dd4c4f7aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qd4982518</td>\n",
       "      <td>dd4ba3af4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qd4982518</td>\n",
       "      <td>dd4bf84f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46705</th>\n",
       "      <td>q1a73d3ea</td>\n",
       "      <td>d1b3b712a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46706</th>\n",
       "      <td>q1a73d3ea</td>\n",
       "      <td>d1b35f90c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46707</th>\n",
       "      <td>q1a73d3ea</td>\n",
       "      <td>d1a73d426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46708</th>\n",
       "      <td>q1a73d3ea</td>\n",
       "      <td>d1b3858e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46709</th>\n",
       "      <td>q1a73d3ea</td>\n",
       "      <td>d1b3c8146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46710 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        query_id  corpus_id\n",
       "0      qd4982518  dd4c4fb38\n",
       "1      qd4982518  dd4c4ef80\n",
       "2      qd4982518  dd4c4f7aa\n",
       "3      qd4982518  dd4ba3af4\n",
       "4      qd4982518  dd4bf84f0\n",
       "...          ...        ...\n",
       "46705  q1a73d3ea  d1b3b712a\n",
       "46706  q1a73d3ea  d1b35f90c\n",
       "46707  q1a73d3ea  d1a73d426\n",
       "46708  q1a73d3ea  d1b3858e6\n",
       "46709  q1a73d3ea  d1b3c8146\n",
       "\n",
       "[46710 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rank = pd.read_csv('./data/final_submission.csv', index_col=False)\n",
    "final_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341896ce-930e-41b2-a0ce-d414be302267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed\n"
     ]
    }
   ],
   "source": [
    "convfinqa_task = ConvFinQA()\n",
    "finbench_task = FinanceBench()\n",
    "finder_task = FinDER()\n",
    "finqa_task = FinQA()\n",
    "finqabench_task = FinQABench()\n",
    "multih_task = MultiHiertt()\n",
    "tatqa_task = TATQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46d5a109-2273-4b18-b72d-fb82e28e019c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m finqabench_task\u001b[38;5;241m.\u001b[39mqueries\u001b[38;5;241m.\u001b[39mvalues()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_values' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "finqabench_task.queries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609690a3-95b5-4b43-8782-40f73f9d4e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>qu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.889597</td>\n",
       "      <td>What is the redemption price for the 0.875% 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0.095079</td>\n",
       "      <td>What is the maturity date of the 0.875% 2025 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>0.955969</td>\n",
       "      <td>What are the conditions under which the Compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.557517</td>\n",
       "      <td>What is the Company's investment policy and st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>0.967048</td>\n",
       "      <td>What is the purpose of the Company's internal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>82</td>\n",
       "      <td>0.486604</td>\n",
       "      <td>What risks are associated with the Company's i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>77</td>\n",
       "      <td>0.206261</td>\n",
       "      <td>What percentage of outstanding shares must vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>93</td>\n",
       "      <td>0.724806</td>\n",
       "      <td>What is the minimum percentage of shares requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>0.323131</td>\n",
       "      <td>What was the approximate dollar value of share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>36</td>\n",
       "      <td>0.520993</td>\n",
       "      <td>What is the \"Par Call Date\" for the 0.875% 202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column1   Column2                                                 qu\n",
       "0         3  0.889597  What is the redemption price for the 0.875% 20...\n",
       "1        39  0.095079  What is the maturity date of the 0.875% 2025 N...\n",
       "2        83  0.955969  What are the conditions under which the Compan...\n",
       "3        12  0.557517  What is the Company's investment policy and st...\n",
       "4        81  0.967048  What is the purpose of the Company's internal ...\n",
       "..      ...       ...                                                ...\n",
       "95       82  0.486604  What risks are associated with the Company's i...\n",
       "96       77  0.206261  What percentage of outstanding shares must vot...\n",
       "97       93  0.724806  What is the minimum percentage of shares requi...\n",
       "98        3  0.323131  What was the approximate dollar value of share...\n",
       "99       36  0.520993  What is the \"Par Call Date\" for the 0.875% 202...\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "random_data = {\n",
    "    \"Column1\": np.random.randint(1, 101, 100),  # 1~100 사이의 랜덤 정수\n",
    "    \"Column2\": np.random.random(100)           # 0~1 사이의 랜덤 실수\n",
    "}\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(random_data)\n",
    "df['qu'] = finqabench_task.queries.values()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111830b8-498c-4585-aa5f-cb24712dc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "convfinqa_results = final_rank.iloc[:4210]\n",
    "finbench_results = final_rank.iloc[4210:6370]\n",
    "finder_results = final_rank.iloc[6370:17870]\n",
    "finqa_results = final_rank.iloc[17870:18870]\n",
    "finqabench_results = final_rank.iloc[18870:20370]\n",
    "multih_results = final_rank.iloc[20370:30110]\n",
    "tatqa_results = final_rank.iloc[30110:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd0f17b-688f-4248-a092-e0cfce75ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confinqa_dict = {}\n",
    "for key in convfinqa_results['query_id'].unique():\n",
    "    group = convfinqa_results[convfinqa_results['query_id'] == key]\n",
    "    confinqa_dict[key] = {value: idx for idx, value in enumerate(group['corpus_id'], start=1)}\n",
    "\n",
    "finbench_dict = {}\n",
    "for key in finbench_results['query_id'].unique():\n",
    "    group = finbench_results[finbench_results['query_id'] == key]\n",
    "    finbench_dict[key] = {value: idx for idx, value in enumerate(group['corpus_id'], start=1)}\n",
    "\n",
    "finder_dict = {}\n",
    "for key in finder_results['query_id'].unique():\n",
    "    group = finder_results[finder_results['query_id'] == key]\n",
    "    finder_dict[key] = {value: idx for idx, value in enumerate(group['corpus_id'], start=1)}\n",
    "\n",
    "finqa_dict = {}\n",
    "for key in finqa_results['query_id'].unique():\n",
    "    group = finqa_results[finqa_results['query_id'] == key]\n",
    "    finqa_dict[key] = {value: idx for idx, value in enumerate(group['corpus_id'], start=1)}\n",
    "\n",
    "finqabench_dict = {}\n",
    "for key in finqabench_results['query_id'].unique():\n",
    "    group = finqabench_results[finqabench_results['query_id'] == key]\n",
    "    finqabench_dict[key] = {value: idx for idx, value in enumerate(group['corpus_id'], start=1)}\n",
    "\n",
    "multih_dict = {}\n",
    "for key in multih_results['query_id'].unique():\n",
    "    group = multih_results[multih_results['query_id'] == key]\n",
    "    multih_dict[key] = {value: idx for idx, value in enumerate(group['corpus_id'], start=1)}\n",
    "\n",
    "tatqa_dict = {}\n",
    "for key in tatqa_results['query_id'].unique():\n",
    "    group = tatqa_results[tatqa_results['query_id'] == key]\n",
    "    tatqa_dict[key] = {value: idx for idx, value in enumerate(group['corpus_id'], start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "564604f3-89c4-43ee-be28-9fa94335990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convfinqa_task.rerank_results = confinqa_dict\n",
    "finbench_task.rerank_results = finbench_dict\n",
    "finder_task.rerank_results = finder_dict\n",
    "finqa_task.rerank_results = finqa_dict\n",
    "finqabench_task.rerank_results = finqabench_dict\n",
    "multih_task.rerank_results = multih_dict\n",
    "tatqa_task.rerank_results = tatqa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2c9af5-72a3-4643-8ff6-f3d83739d03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fc0aa57f2649748fe2820fbc5924b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bdc77711e8468099e1e755f94a8715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1f9a4ec2a44d27b57bf42609316238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0041e1d6408470697e1912d9ee1676b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48893c1a43184314b6459671eeee13ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7853ac2c89c4a829cce90d3f513926b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "INFO:financerag.generate.generator:총 2개의 쿼리에 대해 32개 프로세스를 활용해 답변 생성을 시작합니다.\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-1B-Instruct/v1/chat/completions (Request ID: bZ3G_-i_jmmadt_HBu7T9)\n\nFailed to deserialize the JSON body into the target type: messages: invalid type: map, expected a sequence at line 1 column 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/envs/DSC/lib/python3.12/site-packages/huggingface_hub/utils/_http.py\", line 406, in hf_raise_for_status\n    response.raise_for_status()\n  File \"/opt/conda/envs/DSC/lib/python3.12/site-packages/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-1B-Instruct/v1/chat/completions\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/conda/envs/DSC/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/envs/DSC/lib/python3.12/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/data/DSC/Financerag/financerag/generate/generator.py\", line 62, in _process_query\n    response = client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/envs/DSC/lib/python3.12/site-packages/huggingface_hub/inference/_client.py\", line 882, in chat_completion\n    data = self.post(model=model_url, json=payload, stream=stream)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/envs/DSC/lib/python3.12/site-packages/huggingface_hub/inference/_client.py\", line 296, in post\n    hf_raise_for_status(response)\n  File \"/opt/conda/envs/DSC/lib/python3.12/site-packages/huggingface_hub/utils/_http.py\", line 477, in hf_raise_for_status\n    raise _format(HfHubHTTPError, str(e), response) from e\nhuggingface_hub.errors.HfHubHTTPError: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-1B-Instruct/v1/chat/completions (Request ID: bZ3G_-i_jmmadt_HBu7T9)\n\nFailed to deserialize the JSON body into the target type: messages: invalid type: map, expected a sequence at line 1 column 58\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m example_messages \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq1\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m인공지능이 뭐야?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     }\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m generator \u001b[38;5;241m=\u001b[39m CustomGenerator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.2-1B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m answers \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mgeneration(example_messages, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===== 결과 =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q_id, ans \u001b[38;5;129;01min\u001b[39;00m answers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/data/DSC/Financerag/financerag/generate/generator.py:104\u001b[0m, in \u001b[0;36mCustomGenerator.generation\u001b[0;34m(self, messages, num_processes, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m query_args \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     99\u001b[0m     (q_id, cast(Dict[\u001b[38;5;28mstr\u001b[39m, Any], msg), kwargs\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m q_id, msg \u001b[38;5;129;01min\u001b[39;00m messages\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    101\u001b[0m ]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mnum_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 104\u001b[0m     results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_query, query_args)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m {q_id: answer \u001b[38;5;28;01mfor\u001b[39;00m q_id, answer \u001b[38;5;129;01min\u001b[39;00m results}\n\u001b[1;32m    108\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모든 쿼리에 대한 답변 생성 완료. 총 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개의 결과를 수집했습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, mapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-1B-Instruct/v1/chat/completions (Request ID: bZ3G_-i_jmmadt_HBu7T9)\n\nFailed to deserialize the JSON body into the target type: messages: invalid type: map, expected a sequence at line 1 column 58"
     ]
    }
   ],
   "source": [
    "example_messages = {\n",
    "    \"q1\": {\n",
    "        \"query\": \"인공지능이 뭐야?\",\n",
    "        \"document\": \"인공지능(AI)은 컴퓨터가 인간의 지적 능력을 모방하는 기술이다.\",\n",
    "        \"prompt\": \"아래 문서를 참조해서 사용자의 질문에 답변해줘.\"\n",
    "    },\n",
    "    \"q2\": {\n",
    "        \"query\": \"Mistral 모델에 대해 알려줘\",\n",
    "        \"document\": \"Mistral은 메타 AI에서 선보인 모델로 경량화와 효율성이 특징이다.\",\n",
    "        \"prompt\": \"주어진 문서를 요약하여 사용자 질문에 답변을 작성해줘.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "generator = CustomGenerator(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "answers = generator.generation(example_messages, max_new_tokens=128, temperature=0.7)\n",
    "\n",
    "print(\"===== 결과 =====\")\n",
    "for q_id, ans in answers.items():\n",
    "    print(f\"- Query ID: {q_id}\\n  Generated Answer: {ans}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0682f3d-3262-46d6-a0dd-0608b2f1f3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c439e8-5846-4174-b516-af7ddc9f1c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0636fce-d9f7-4547-a22f-9973a9f51e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d6264-93d7-4bef-86c1-5047127f37a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12018a-f9b9-4fbb-a1d9-8bcefa81f9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fe9de-9c82-4a3b-bf7f-ddb3b9794a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d5b3c-ae67-4cd9-abf6-d0748856a0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e2ad7-60ca-4a4d-adfb-a3970acadf00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493246d-5b6b-4027-b385-a0e4dc9a1ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bc404-17c8-4377-ba0b-778d0d6ea7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d2836-6a16-4757-9fd4-d58d8cb94c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8078c10-c614-4544-af4d-23cec196d35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSC",
   "language": "python",
   "name": "dsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
