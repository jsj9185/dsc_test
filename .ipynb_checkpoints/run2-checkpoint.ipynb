{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fef226c-e266-4e40-9c6e-9958306ccfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-m3\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 23.70 GiB of which 6.56 MiB is free. Process 24152 has 2.67 GiB memory in use. Process 3927 has 3.47 GiB memory in use. Process 4552 has 17.55 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 8.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m base_encoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAAI/bge-m3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#\"BAAI/bge-m3\" # \"intfloat/multilingual-e5-large-instruct\"  #\"BAAI/bge-large-en-v1.5\" #\"nvidia/NV-Embed-v2\"(20GB) \"intfloat/e5-mistral-7b-instruct\"(9GB) \u001b[39;00m\n\u001b[1;32m     31\u001b[0m                                             \u001b[38;5;66;03m#\"dunzhang/stella_en_1.5B_v5\" (6GB)  \"jinaai/jina-embeddings-v3\"(1.1GB) \"jinaai/jina-embeddings-v2-base-code\"(320MB)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m encoder_model \u001b[38;5;241m=\u001b[39m SentenceTransformerEncoder(\n\u001b[1;32m     33\u001b[0m     model_name_or_path\u001b[38;5;241m=\u001b[39mbase_encoder,\n\u001b[1;32m     34\u001b[0m     query_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery: \u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m     doc_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassage: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m retrieval_model \u001b[38;5;241m=\u001b[39m DenseRetrieval(\n\u001b[1;32m     39\u001b[0m     model\u001b[38;5;241m=\u001b[39mencoder_model,\n\u001b[1;32m     40\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mencoding_batch_size\n\u001b[1;32m     41\u001b[0m  )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m###################################################################################\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Run Retrieval\u001b[39;00m\n",
      "File \u001b[0;32m/data/DSC/Financerag/financerag/retrieval/sent_encoder.py:21\u001b[0m, in \u001b[0;36mSentenceTransformerEncoder.__init__\u001b[0;34m(self, model_name_or_path, query_prompt, doc_prompt, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     15\u001b[0m         model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_name_or_path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_model\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_name_or_path, Tuple):\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:333\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (5 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/DSC/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1327\u001b[0m         device,\n\u001b[1;32m   1328\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1329\u001b[0m         non_blocking,\n\u001b[1;32m   1330\u001b[0m     )\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 23.70 GiB of which 6.56 MiB is free. Process 24152 has 2.67 GiB memory in use. Process 3927 has 3.47 GiB memory in use. Process 4552 has 17.55 GiB memory in use. Of the allocated memory 16.40 GiB is allocated by PyTorch, and 8.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch, gc\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder, BM25Retriever, HybridRetriever\n",
    "from financerag.tasks import ConvFinQA, FinanceBench, FinDER, FinQA, FinQABench, MultiHiertt, TATQA\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "encoding_batch_size=128\n",
    "rerank1_batch_size=32\n",
    "rerank2_batch_size=16\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "###################################################################################\n",
    "convfinqa_task = ConvFinQA()\n",
    "finbench_task = FinanceBench()\n",
    "finder_task = FinDER()\n",
    "finqa_task = FinQA()\n",
    "finqabench_task = FinQABench()\n",
    "multih_task = MultiHiertt()\n",
    "tatqa_task = TATQA()\n",
    "###################################################################################\n",
    "# Encoder & retrieval\n",
    "base_encoder = \"BAAI/bge-m3\" #\"BAAI/bge-m3\" # \"intfloat/multilingual-e5-large-instruct\"  #\"BAAI/bge-large-en-v1.5\" #\"nvidia/NV-Embed-v2\"(20GB) \"intfloat/e5-mistral-7b-instruct\"(9GB) \n",
    "                                            #\"dunzhang/stella_en_1.5B_v5\" (6GB)  \"jinaai/jina-embeddings-v3\"(1.1GB) \"jinaai/jina-embeddings-v2-base-code\"(320MB)\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path=base_encoder,\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: '\n",
    ")\n",
    "\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model,\n",
    "    batch_size=encoding_batch_size\n",
    " )\n",
    "###################################################################################\n",
    "# Run Retrieval\n",
    "print(\"Working on ConvfinQA Task\")\n",
    "convfinqa_result = convfinqa_task.retrieve(\n",
    "    retriever=retrieval_model,\n",
    "    top_k=int(len(convfinqa_task.corpus)*0.6))\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Working on FinBench Task\")\n",
    "finbench_result = finbench_task.retrieve(\n",
    "    retriever=retrieval_model,\n",
    "    top_k=int(len(finbench_task.corpus)*0.9))\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Working on FinDER Task\")\n",
    "finder_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model,\n",
    "    top_k=int(len(finder_task.corpus)*0.3))\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Working on FinQA Task\")\n",
    "finqa_result = finqa_task.retrieve(\n",
    "    retriever=retrieval_model,\n",
    "    top_k=int(len(finqa_task.corpus)*0.6))\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Working on FinQABench Task\")\n",
    "finqabench_result = finqabench_task.retrieve(\n",
    "    retriever=retrieval_model,\n",
    "    top_k=int(len(finqabench_task.corpus)*0.8))\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Working on MultiHiertt Task\")\n",
    "multih_result = multih_task.retrieve(\n",
    "    retriever=retrieval_model,\n",
    "    top_k=int(len(multih_task.corpus)*0.3))\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Working on TATQA Task\")\n",
    "tatqa_result = tatqa_task.retrieve(\n",
    "    retriever=retrieval_model,\n",
    "    top_k=int(len(tatqa_task.corpus)*0.5))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "results = [\n",
    "    convfinqa_result,\n",
    "    finbench_result,\n",
    "    finder_result,\n",
    "    finqa_result,\n",
    "    finqabench_result,\n",
    "    multih_result,\n",
    "    tatqa_result\n",
    "]\n",
    "###################################################################################\n",
    "def get_evalset(dataset_name):\n",
    "    qrels = {}\n",
    "    df_qrels = pd.read_csv(f\"./data/test/{dataset_name}_qrels.tsv\", sep='\\t')\n",
    "    for _, row in df_qrels.iterrows():\n",
    "        if row['query_id'] not in qrels:\n",
    "            qrels[row['query_id']] = {}\n",
    "        qrels[row['query_id']][row['corpus_id']] = row['score']\n",
    "    return qrels\n",
    "\n",
    "tasks = [\n",
    "    convfinqa_task,\n",
    "    finbench_task,\n",
    "    finder_task,\n",
    "    finqa_task,\n",
    "    finqabench_task,\n",
    "    multih_task,\n",
    "    tatqa_task\n",
    "]\n",
    "\n",
    "qrels = [\n",
    "    get_evalset('ConvFinQA'),\n",
    "    get_evalset('FinanceBench'),\n",
    "    get_evalset('FinDER'),\n",
    "    get_evalset('FinQA'),\n",
    "    get_evalset('FinQABench'),\n",
    "    get_evalset('MultiHeirtt'),\n",
    "    get_evalset('TATQA')\n",
    "]\n",
    "\n",
    "ndcg_values = []\n",
    "map_values = []\n",
    "recall_values = []\n",
    "precision_values = []\n",
    "\n",
    "dataset_names = [\n",
    "    'ConvFinQA',\n",
    "    'FinanceBench',\n",
    "    'FinDER',\n",
    "    'FinQA',\n",
    "    'FinQABench',\n",
    "    'MultiHeirtt',\n",
    "    'TATQA'\n",
    "]\n",
    "\n",
    "for qrel, task in zip(qrels, tasks):\n",
    "    metrics = task.evaluate(qrels=qrel, results=task.retrieve_results, k_values=[10])\n",
    "    ndcg_values.append(metrics[0]['NDCG@10'])  # NDCG@10\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(ndcg_values, marker='o', label='NDCG@10', color='b')\n",
    "plt.title('NDCG@10')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(range(len(dataset_names)), dataset_names, rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "###################################################################################\n",
    "base_reranker = \"BAAI/bge-reranker-base\" #\"BAAI/bge-reranker-base\" #m2 \n",
    "\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder(base_reranker))\n",
    "###################################################################################\n",
    "# Step 6: Perform reranking 1\n",
    "batch_size = rerank1_batch_size # 32\n",
    "\n",
    "print(\"\\nWorking on ConvFinQA Reranking\")\n",
    "retrieve_k = len(list(convfinqa_task.retrieve_results.values())[0])\n",
    "top_k = int(0.6 * retrieve_k)\n",
    "convfinqa_rerank = convfinqa_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=convfinqa_result,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinBench Reranking\")\n",
    "retrieve_k = len(list(finbench_task.retrieve_results.values())[0])\n",
    "top_k = int(0.8 * retrieve_k)\n",
    "finbench_rerank = finbench_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=finbench_result,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinDER Reranking\")\n",
    "retrieve_k = len(list(finder_task.retrieve_results.values())[0])\n",
    "top_k = int(0.4 * retrieve_k)\n",
    "finder_rerank = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=finder_result,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinQA Reranking\")\n",
    "retrieve_k = len(list(finqa_task.retrieve_results.values())[0])\n",
    "top_k = int(0.6 * retrieve_k)\n",
    "finqa_rerank = finqa_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=finqa_result,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinQABench Reranking\")\n",
    "retrieve_k = len(list(finqabench_task.retrieve_results.values())[0])\n",
    "top_k = int(0.8 * retrieve_k)\n",
    "finqabench_rerank = finqabench_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=finqabench_result,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on MultiHiertt Reranking\")\n",
    "retrieve_k = len(list(multih_task.retrieve_results.values())[0])\n",
    "top_k = int(0.4 * retrieve_k)\n",
    "multih_rerank = multih_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=multih_result,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on TATQA Reranking\")\n",
    "retrieve_k = len(list(tatqa_task.retrieve_results.values())[0])\n",
    "top_k = int(0.6 * retrieve_k)\n",
    "tatqa_rerank = tatqa_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=tatqa_result,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "reranking_results = [\n",
    "    convfinqa_rerank,\n",
    "    finbench_rerank,\n",
    "    finder_rerank,\n",
    "    finqa_rerank,\n",
    "    finqabench_rerank,\n",
    "    multih_rerank,\n",
    "    tatqa_rerank\n",
    "]\n",
    "###################################################################################\n",
    "retrieval_ndcg_values = []\n",
    "rerank_ndcg_values = []\n",
    "\n",
    "retrieval_map_values = []\n",
    "rerank_map_values = []\n",
    "\n",
    "retrieval_recall_values = []\n",
    "rerank_recall_values = []\n",
    "\n",
    "retrieval_precision_values = []\n",
    "rerank_precision_values = []\n",
    "\n",
    "# 데이터셋 이름 리스트\n",
    "dataset_names = [\n",
    "    'ConvFinQA',\n",
    "    'FinanceBench',\n",
    "    'FinDER',\n",
    "    'FinQA',\n",
    "    'FinQABench',\n",
    "    'MultiHeirtt',\n",
    "    'TATQA'\n",
    "]\n",
    "\n",
    "for qrel, task in zip(qrels, tasks):\n",
    "    # 평가지표 평가 (retrieval 결과)\n",
    "    #retrieval_metrics = task.evaluate(qrels=qrel, results=task.retrieve_results, k_values=[10])\n",
    "    \n",
    "    # 평가지표 평가 (rerank 결과)\n",
    "    rerank_metrics = task.evaluate(qrels=qrel, results=task.rerank_results, k_values=[10])\n",
    "\n",
    "    # retrieval_ndcg_values.append(retrieval_metrics[0]['NDCG@10'])\n",
    "    # retrieval_map_values.append(retrieval_metrics[1]['MAP@10'])\n",
    "    # retrieval_recall_values.append(retrieval_metrics[2]['Recall@10'])\n",
    "    # retrieval_precision_values.append(retrieval_metrics[3]['P@10'])\n",
    "    \n",
    "    rerank_ndcg_values.append(rerank_metrics[0]['NDCG@10'])\n",
    "    rerank_map_values.append(rerank_metrics[1]['MAP@10'])\n",
    "    rerank_recall_values.append(rerank_metrics[2]['Recall@10'])\n",
    "    rerank_precision_values.append(rerank_metrics[3]['P@10'])\n",
    "\n",
    "# 그래프 생성\n",
    "plt.figure(figsize=(14, 10))\n",
    "#plt.plot(retrieval_ndcg_values, marker='o', label='Retrieval NDCG@10', color='b')\n",
    "plt.plot(rerank_ndcg_values, marker='x', label='Rerank NDCG@10', color='b', linestyle='--')\n",
    "plt.title('NDCG@10 Comparison')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(range(len(dataset_names)), dataset_names, rotation=45)  # X축에 데이터셋 이름을 설정\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "###################################################################################\n",
    "base_reranker2 = \"BAAI/bge-reranker-v2-m3\" # \"BAAI/bge-reranker-base\" #\"jinaai/jina-reranker-v2-base-multilingual\" #'cross-encoder/ms-marco-MiniLM-L-12-v2' #\"BAAI/bge-reranker-base\"\n",
    "\n",
    "reranker2 = CrossEncoderReranker(\n",
    "    model=CrossEncoder(base_reranker2))\n",
    "###################################################################################\n",
    "# Step 6: Perform reranking\n",
    "\n",
    "top_k= 15 # Number of Reranking results\n",
    "batch_size = rerank2_batch_size # 32\n",
    "\n",
    "print(\"\\nWorking on ConvFinQA Reranking\")\n",
    "convfinqa_rerank_second = convfinqa_task.rerank(\n",
    "    reranker=reranker2,\n",
    "    results=convfinqa_rerank,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinBench Reranking\")\n",
    "finbench_rerank_second = finbench_task.rerank(\n",
    "    reranker=reranker2,\n",
    "    results=finbench_rerank,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinDER Reranking\")\n",
    "finder_rerank_second = finder_task.rerank(\n",
    "    reranker=reranker2,\n",
    "    results=finder_rerank,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinQA Reranking\")\n",
    "finqa_rerank_second = finqa_task.rerank(\n",
    "    reranker=reranker2,\n",
    "    results=finqa_rerank,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on FinQABench Reranking\")\n",
    "finqabench_rerank_second = finqabench_task.rerank(\n",
    "    reranker=reranker2,\n",
    "    results=finqabench_rerank,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on MultiHiertt Reranking\")\n",
    "multih_rerank_second = multih_task.rerank(\n",
    "    reranker=reranker2,\n",
    "    results=multih_rerank,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nWorking on TATQA Reranking\")\n",
    "tatqa_rerank_second = tatqa_task.rerank(\n",
    "    reranker=reranker2,\n",
    "    results=tatqa_rerank,\n",
    "    top_k=top_k,  # Rerank the top 100 documents\n",
    "    batch_size=batch_size\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "reranking_results_second = [\n",
    "    convfinqa_rerank_second,\n",
    "    finbench_rerank_second,\n",
    "    finder_rerank_second,\n",
    "    finqa_rerank_second,\n",
    "    finqabench_rerank_second,\n",
    "    multih_rerank_second,\n",
    "    tatqa_rerank_second\n",
    "]\n",
    "###################################################################################\n",
    "rerank_second_ndcg_values = []\n",
    "\n",
    "dataset_names = [\n",
    "    'ConvFinQA',\n",
    "    'FinanceBench',\n",
    "    'FinDER',\n",
    "    'FinQA',\n",
    "    'FinQABench',\n",
    "    'MultiHeirtt',\n",
    "    'TATQA'\n",
    "]\n",
    "\n",
    "for qrel, task in zip(qrels, tasks):\n",
    "    rerank_second_metrics = task.evaluate(qrels=qrel, results=task.rerank_results, k_values=[10])\n",
    "    rerank_second_ndcg_values.append(rerank_second_metrics[0]['NDCG@10'])\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.plot(retrieval_ndcg_values, marker='o', label='Retrieval NDCG@10', color='b')\n",
    "plt.plot(rerank_ndcg_values, marker='x', label='Rerank NDCG@10', color='b', linestyle='--')\n",
    "plt.plot(rerank_second_ndcg_values, marker='s', label='Rerank Second NDCG@10', color='b', linestyle='-.')\n",
    "plt.title('NDCG@10 Comparison')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(range(len(dataset_names)), dataset_names, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###################################################################################\n",
    "# Step 7: Save results\n",
    "results_dir = './financerag/results/'\n",
    "time_obj = datetime.now()\n",
    "subfolder = \"submission_\" + time_obj.strftime('%m%d%H%M')\n",
    "output_dir = results_dir + subfolder\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results_df = [\n",
    "    convfinqa_task.load_results(),\n",
    "    finbench_task.load_results(),\n",
    "    finder_task.load_results(),\n",
    "    finqa_task.load_results(),\n",
    "    finqabench_task.load_results(),\n",
    "    multih_task.load_results(),\n",
    "    tatqa_task.load_results()\n",
    "]\n",
    "\n",
    "combined_df = pd.concat(results_df, ignore_index=False)\n",
    "combined_df.to_csv(output_dir + '/' + subfolder + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a98e536-d8f8-47b6-9d76-fa87589a6826",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Reranker' from 'jina' (/opt/conda/envs/DSC/lib/python3.12/site-packages/jina/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjina\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reranker\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjina\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentArray, Document\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Reranker' from 'jina' (/opt/conda/envs/DSC/lib/python3.12/site-packages/jina/__init__.py)"
     ]
    }
   ],
   "source": [
    "from jina import Reranker\n",
    "from jina.types.document import DocumentArray, Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41bda830-cd12-4856-b254-9dfcbab51b53",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Reranker' from 'jina' (/opt/conda/envs/DSC/lib/python3.12/site-packages/jina/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjina\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reranker\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjina\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentArray, Document\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 모델을 로드\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Reranker' from 'jina' (/opt/conda/envs/DSC/lib/python3.12/site-packages/jina/__init__.py)"
     ]
    }
   ],
   "source": [
    "from jina import Reranker\n",
    "from jina.types.document import DocumentArray, Document\n",
    "\n",
    "# 모델을 로드\n",
    "model_name = \"jinaai/jina-reranker-v2-base-multilingual\"\n",
    "reranker = Reranker(model_name=model_name)\n",
    "\n",
    "# 사용할 예제 쿼리와 문서\n",
    "query = \"What is the capital of France?\"\n",
    "documents = [\"Paris is the capital of France.\", \"Berlin is the capital of Germany.\", \"Madrid is the capital of Spain.\"]\n",
    "\n",
    "# 문서 점수 매기기\n",
    "results = reranker.rank(query, documents)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Ranked results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d67730-4571-4bf7-b750-72d50ae9fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'jinaai/jina-reranker-v2-base-multilingual',\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    use_flash_attn=False\n",
    ")\n",
    "\n",
    "model.to('cuda') # or 'cpu' if no GPU is available\n",
    "model.eval()\n",
    "\n",
    "# Example query and documents\n",
    "query = \"Organic skincare products for sensitive skin\"\n",
    "documents = [\n",
    "    \"Organic skincare for sensitive skin with aloe vera and chamomile.\",\n",
    "    \"New makeup trends focus on bold colors and innovative techniques\",\n",
    "    \"Bio-Hautpflege für empfindliche Haut mit Aloe Vera und Kamille\",\n",
    "    \"Neue Make-up-Trends setzen auf kräftige Farben und innovative Techniken\",\n",
    "    \"Cuidado de la piel orgánico para piel sensible con aloe vera y manzanilla\",\n",
    "    \"Las nuevas tendencias de maquillaje se centran en colores vivos y técnicas innovadoras\",\n",
    "    \"针对敏感肌专门设计的天然有机护肤产品\",\n",
    "    \"新的化妆趋势注重鲜艳的颜色和创新的技巧\",\n",
    "    \"敏感肌のために特別に設計された天然有機スキンケア製品\",\n",
    "    \"新しいメイクのトレンドは鮮やかな色と革新的な技術に焦点を当てています\",\n",
    "]\n",
    "\n",
    "# construct sentence pairs\n",
    "sentence_pairs = [[query, doc] for doc in documents]\n",
    "\n",
    "scores = model.compute_score(sentence_pairs, max_length=1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSC",
   "language": "python",
   "name": "dsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
