{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:50:33.702172Z",
     "iopub.status.busy": "2024-10-04T14:50:33.701317Z",
     "iopub.status.idle": "2024-10-04T14:51:15.803357Z",
     "shell.execute_reply": "2024-10-04T14:51:15.802271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# --------------------------------------\n",
    "# Import required libraries for document retrieval, reranking, and logging setup.\n",
    "from importlib import reload\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "\n",
    "import financerag.tasks.Base_Task; reload(financerag.tasks.Base_Task)\n",
    "import financerag.tasks.ConvFinQATask; reload(financerag.tasks.ConvFinQATask)\n",
    "import financerag.tasks.FinanceBenchTask; reload(financerag.tasks.FinanceBenchTask)\n",
    "import financerag.tasks.FinDERTask; reload(financerag.tasks.FinDERTask)\n",
    "import financerag.tasks.FinQATask; reload(financerag.tasks.FinQATask)\n",
    "import financerag.tasks.FinQABenchTask; reload(financerag.tasks.FinQABenchTask)\n",
    "import financerag.tasks.MultiHierttTask; reload(financerag.tasks.MultiHierttTask)\n",
    "import financerag.tasks.TATQATask; reload(financerag.tasks.TATQATask)\n",
    "reload(financerag.tasks)\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from financerag.tasks import FinDER, ConvFinQA\n",
    "\n",
    "# Setup basic logging configuration to show info level messages.\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'containerboard , kraft papers and saturating kraft .\\nkapstone also owns victory packaging , a packaging solutions distribution company with facilities in the u.s. , canada and mexico .\\nwe have included the financial results of kapstone in our corrugated packaging segment since the date of the acquisition .\\non september 4 , 2018 , we completed the acquisition ( the 201cschl fcter acquisition 201d ) of schl fcter print pharma packaging ( 201cschl fcter 201d ) .\\nschl fcter is a leading provider of differentiated paper and packaging solutions and a german-based supplier of a full range of leaflets and booklets .\\nthe schl fcter acquisition allowed us to further enhance our pharmaceutical and automotive platform and expand our geographical footprint in europe to better serve our customers .\\nwe have included the financial results of the acquired operations in our consumer packaging segment since the date of the acquisition .\\non january 5 , 2018 , we completed the acquisition ( the 201cplymouth packaging acquisition 201d ) of substantially all of the assets of plymouth packaging , inc .\\n( 201cplymouth 201d ) .\\nthe assets we acquired included plymouth 2019s 201cbox on demand 201d systems , which are manufactured by panotec , an italian manufacturer of packaging machines .\\nthe addition of the box on demand systems enhanced our platform , differentiation and innovation .\\nthese systems , which are located on customers 2019 sites under multi-year exclusive agreements , use fanfold corrugated to produce custom , on-demand corrugated packaging that is accurately sized for any product type according to the customer 2019s specifications .\\nfanfold corrugated is continuous corrugated board , folded periodically to form an accordion-like stack of corrugated material .\\nas part of the transaction , westrock acquired plymouth 2019s equity interest in panotec and plymouth 2019s exclusive right from panotec to distribute panotec 2019s equipment in the u.s .\\nand canada .\\nwe have fully integrated the approximately 60000 tons of containerboard used by plymouth annually .\\nwe have included the financial results of plymouth in our corrugated packaging segment since the date of the acquisition .\\nsee 201cnote 3 .\\nacquisitions and investment 201d of the notes to consolidated financial statements for additional information .\\nsee also item 1a .\\n201crisk factors 2014 we may be unsuccessful in making and integrating mergers , acquisitions and investments , and completing divestitures 201d .\\nbusiness .\\n\\nIn the year ended September 30, 2019, net sales were $18,289.0 million, while in the year ended September 30, 2018, net sales were $16,285.1 million. Segment income for the year ended September 30, 2019, was $1,790.2 million, compared to $1,707.6 million for the year ended September 30, 2018.\\n\\nin fiscal 2019 , we continued to pursue our strategy of offering differentiated paper and packaging solutions that help our customers win .\\nwe successfully executed this strategy in fiscal 2019 in a rapidly changing cost and price environment .\\nnet sales of $ 18289.0 million for fiscal 2019 increased $ 2003.9 million , or 12.3% ( 12.3 % ) , compared to fiscal 2018 .\\nthe increase was primarily due to the kapstone acquisition and higher selling price/mix in our corrugated packaging and consumer packaging segments .\\nthese increases were partially offset by the absence of recycling net sales in fiscal 2019 as a result of conducting the operations primarily as a procurement function beginning in the first quarter of fiscal 2019 , lower volumes , unfavorable foreign currency impacts across our segments compared to the prior year and decreased land and development net sales .\\nsegment income increased $ 82.6 million in fiscal 2019 compared to fiscal 2018 , primarily due to increased corrugated packaging segment income that was partially offset by lower consumer packaging and land and development segment income .\\nthe impact of the contribution from the acquired kapstone operations , higher selling price/mix across our segments and productivity improvements was largely offset by lower volumes across our segments , economic downtime , cost inflation , increased maintenance and scheduled strategic outage expense ( including projects at our mahrt , al and covington , va mills ) and lower land and development segment income due to the wind-down of sales .\\nwith respect to segment income , we experienced higher levels of cost inflation in both our corrugated packaging and consumer packaging segments during fiscal 2019 as compared to fiscal 2018 that were partially offset by recovered fiber deflation .\\nthe primary inflationary items were virgin fiber , freight , energy and wage and other costs .\\nwe generated $ 2310.2 million of net cash provided by operating activities in fiscal 2019 , compared to $ 1931.2 million in fiscal 2018 .\\nwe remained committed to our disciplined capital allocation strategy during fiscal '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corpus Test\n",
    "\n",
    "'''import json\n",
    "import os\n",
    "\n",
    "query_path = os.path.join(os.getcwd(), 'data', 'convfinqa', 'corpus.jsonl')\n",
    "\n",
    "with open(query_path, 'r', encoding='utf-8') as f:\n",
    "    queries = [json.loads(line) for line in f]\n",
    "\n",
    "queries[0]['text']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:15.808338Z",
     "iopub.status.busy": "2024-10-04T14:51:15.807849Z",
     "iopub.status.idle": "2024-10-04T14:51:23.956758Z",
     "shell.execute_reply": "2024-10-04T14:51:23.955721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "convfinqa\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize FinDER Task\n",
    "# --------------------------\n",
    "# In this baseline example, we are using the FinDER task, one of the seven available tasks in this project.\n",
    "# If you want to use a different task, for example, 'OtherTask', you can change the task initialization as follows:\n",
    "#\n",
    "# Example:\n",
    "# from financerag.tasks import OtherTask\n",
    "# finder_task = OtherTask()\n",
    "#\n",
    "# For this baseline, we proceed with FinDER.\n",
    "#finder_task = FinDER()\n",
    "convfinqa_task = ConvFinQA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'finder_task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m finder_task\n",
      "\u001b[1;31mNameError\u001b[0m: name 'finder_task' is not defined"
     ]
    }
   ],
   "source": [
    "finder_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:23.961016Z",
     "iopub.status.busy": "2024-10-04T14:51:23.960728Z",
     "iopub.status.idle": "2024-10-04T14:51:39.063618Z",
     "shell.execute_reply": "2024-10-04T14:51:39.062302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-large-v2\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize DenseRetriever model\n",
    "# -------------------------------------\n",
    "# Initialize the retrieval model using SentenceTransformers. This model will be responsible\n",
    "# for encoding both the queries and documents into embeddings.\n",
    "#\n",
    "# You can replace 'intfloat/e5-large-v2' with any other model supported by SentenceTransformers.\n",
    "# For example: 'BAAI/bge-large-en-v1.5', 'Linq-AI-Research/Linq-Embed-Mistral', etc.\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path='intfloat/e5-large-v2',\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: ',\n",
    ")\n",
    "\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:39.068549Z",
     "iopub.status.busy": "2024-10-04T14:51:39.068124Z",
     "iopub.status.idle": "2024-10-04T14:54:07.488228Z",
     "shell.execute_reply": "2024-10-04T14:54:07.486678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.dense:Encoding queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2311a71bc5d4f678cd6f820f6f50f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\God_YJ\\anaconda3\\envs\\fsi\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d9544a47314002b1c2e2dbc4cad1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved results for 216 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = MSFT20230966, Score = 0.873996376991272\n",
      "  Document 2: Document ID = MSFT20230216, Score = 0.8645688891410828\n",
      "  Document 3: Document ID = MSFT20230015, Score = 0.8594436049461365\n",
      "  Document 4: Document ID = MSFT20230254, Score = 0.8580107092857361\n",
      "  Document 5: Document ID = MSFT20230155, Score = 0.8534095883369446\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform retrieval\n",
    "# ---------------------\n",
    "# Use the model to retrieve relevant documents for given queries.\n",
    "\n",
    "retrieval_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model\n",
    ")\n",
    "\n",
    "# Print a portion of the retrieval results to verify the output.\n",
    "print(f\"Retrieved results for {len(retrieval_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in retrieval_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:07.495914Z",
     "iopub.status.busy": "2024-10-04T14:54:07.494072Z",
     "iopub.status.idle": "2024-10-04T14:54:09.186831Z",
     "shell.execute_reply": "2024-10-04T14:54:09.185722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf1b50571294d46b261aeee98f09106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\God_YJ\\anaconda3\\envs\\fsi\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\God_YJ\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd8a132b0334714a7f9a8051394daed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8791a05242ea40999a3df53bccd572ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e42674106654fd6b34efe1aa21ec044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6c764c0c9c43f29c35da6b962f7acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\God_YJ\\anaconda3\\envs\\fsi\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Initialize CrossEncoder Reranker\n",
    "# --------------------------------------\n",
    "# The CrossEncoder model will be used to rerank the retrieved documents based on relevance.\n",
    "#\n",
    "# You can replace 'cross-encoder/ms-marco-MiniLM-L-12-v2' with any other model supported by CrossEncoder.\n",
    "# For example: 'cross-encoder/ms-marco-TinyBERT-L-2', 'cross-encoder/stsb-roberta-large', etc.\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:09.190909Z",
     "iopub.status.busy": "2024-10-04T14:54:09.190659Z",
     "iopub.status.idle": "2024-10-04T14:54:54.978852Z",
     "shell.execute_reply": "2024-10-04T14:54:54.977781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497c5acbb1f04418a49bec07d72a9380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking results for 216 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = MSFT20230254, Score = 6.622737884521484\n",
      "  Document 2: Document ID = MSFT20230233, Score = 6.0889434814453125\n",
      "  Document 3: Document ID = MSFT20230230, Score = 5.898367404937744\n",
      "  Document 4: Document ID = MSFT20230236, Score = 5.747088432312012\n",
      "  Document 5: Document ID = MSFT20230216, Score = 5.488572120666504\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Perform reranking\n",
    "# -------------------------\n",
    "# Rerank the top 100 retrieved documents using the CrossEncoder model.\n",
    "reranking_result = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=retrieval_result,\n",
    "    top_k=100,  # Rerank the top 100 documents\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Print a portion of the reranking results to verify the output.\n",
    "print(f\"Reranking results for {len(reranking_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in reranking_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:54.989320Z",
     "iopub.status.busy": "2024-10-04T14:54:54.989100Z",
     "iopub.status.idle": "2024-10-04T14:54:55.005455Z",
     "shell.execute_reply": "2024-10-04T14:54:55.004477Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.tasks.BaseTask:Output directory set to: ./results\\FinDER\n",
      "INFO:financerag.tasks.BaseTask:Saving top 10 results to CSV file: ./results\\FinDER\\results.csv\n",
      "INFO:financerag.tasks.BaseTask:Writing header ['query_id', 'corpus_id'] to CSV.\n",
      "INFO:financerag.tasks.BaseTask:Top 10 results saved successfully to ./results\\FinDER\\results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to ./results/FinDER/results.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save results\n",
    "# -------------------\n",
    "# Save the results to the specified output directory as a CSV file.\n",
    "output_dir = './results'\n",
    "finder_task.save_results(output_dir=output_dir)\n",
    "\n",
    "# Confirm the results have been saved.\n",
    "print(f\"Results have been saved to {output_dir}/FinDER/results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9677683,
     "sourceId": 85594,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "fsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
